m = matrix(c(1,2,3,4,5,6,7,8,9), nrow =3 )
newvector = as.vector(m)
new = as.vector(as.matrix.data.frame(m))
new
?rep()
?sort()
grades
numLlvs <- 4
confusionMatrix(
factor(sample(rep(letters[1:numLlvs], 200), 50)),
factor(sample(rep(letters[1:numLlvs], 200), 50)))
install.packages("confusionMatrix")
library('caret')
numLlvs <- 4
confusionMatrix(
factor(sample(rep(letters[1:numLlvs], 200), 50)),
factor(sample(rep(letters[1:numLlvs], 200), 50)))
sample(rep(letters[1:numLlvs], 200), 50)
sample(rep(letters[1:numLlvs], 200), 50)
confusionMatrix(
factor(sample(rep(letters[1:numLlvs], 200), 50)),
factor(sample(rep(letters[1:numLlvs], 200), 50)))
library('dplyr')
library('ordinalNet')
### simulation n = 21 ###
#create the dataset with starting quantites, all products and test 1 cp values
sd.val = 0.2
sd.val.test = 0.1
set.seed(1234)
eps = rnorm(21, 0, sd.val)
set.seed(12345)
eps.test= rnorm(21, 0, sd.val.test)
stq =sort(rep(c(0.010, 0.050, 0.100, 0.500, 1.000, 0.005, 5.000), 3))
allp = (-2.5)*log(stq)+25+eps
test1 = -2.7*log(stq)+23+eps.test
#plot the two cp types against log starting quantity
plot( allp,log(stq), col = 'red', main = "Log Starting Quanitty vs. Cp Values",
ylab = "log(Starting Quantity)", xlab = "Cp Values" , xlim = c(15, 45), ylim = c(-6, 2))
points(test1,log(stq), col = 'blue')
abline(lm(log(stq)~allp), col = 'red')
abline(lm(log(stq)~test1), col = 'blue')
legend('topright', legend=c("Test 1", "All Products"),
col=c("blue", "red"), lty = 1, cex=0.8)
# create the data frame and include the z scores of test 1 and all p
# create the data frame and include the z scores of test 1 and all p
data = as.data.frame(cbind(stq, allp, test1))
data$ztest1 = (data$test1 - mean(data$test1))/sd(data$test1)
data$zallP = (data$allp - mean(data$allp))/sd(data$allp)
#define ordinal model starq~zallP+ztest1
covmat = as.matrix(data[, c(4,5)])
ordmod = ordinalNet(covmat, as.factor(data$stq))
summary(ordmod)
coef(ordmod, matrix=TRUE)
#kfold cv
set.seed(123)
ordfit = ordinalNetTune(covmat, as.factor(data$stq), family = "cumulative",
link = "logit", parallelTerms = TRUE, nonparallelTerms = TRUE,
warn = FALSE, printProgress = FALSE)
head(ordfit$loglik)
bestLambdaIndex = which.max(rowMeans(ordfit$loglik))
head(coef(ordfit$fit, matrix = TRUE, whichLambda = bestLambdaIndex))
ordfit = ordinalNetTune(covmat, as.factor(data$stq), family = "cumulative",
link = "logit", parallelTerms = TRUE, nonparallelTerms = TRUE,
warn = FALSE, printProgress = FALSE)
#kfold cv
set.seed(123)
ordfit = ordinalNetTune(covmat, as.factor(data$stq), family = "cumulative",
link = "logit", parallelTerms = TRUE, nonparallelTerms = TRUE,
warn = FALSE, printProgress = FALSE)
l products and test 1 cp values
sd.val = 0.2
sd.val.test = 0.1
set.seed(1234)
eps = rnorm(21, 0, sd.val)
set.seed(12345)
eps.test= rnorm(21, 0, sd.val.test)
stq =sort(rep(c(0.010, 0.050, 0.100, 0.500, 1.000, 0.005, 5.000), 3))
allp = (-2.5)*log(stq)+25+eps
test1 = -2.7*log(stq)+23+eps.test
#plot the two cp types against log starting quantity
plot( allp,log(stq), col = 'red', main = "Log Starting Quanitty vs. Cp Values",
ylab = "log(Starting Quantity)", xlab = "Cp Values" , xlim = c(15, 45), ylim = c(-6, 2))
points(test1,log(stq), col = 'blue')
abline(lm(log(stq)~allp), col = 'red')
abline(lm(log(stq)~test1), col = 'blue')
legend('topright', legend=c("Test 1", "All Products"),
col=c("blue", "red"), lty = 1, cex=0.8)
# create the data frame and include the z scores of test 1 and all p
data = as.data.frame(cbind(stq, allp, test1))
data$ztest1 = (data$test1 - mean(data$test1))/sd(data$test1)
data$zallP = (data$allp - mean(data$allp))/sd(data$allp)
#### Ordinal Net Models ####
## Model 1 ##
#define ordinal model starq~zallP+ztest1
covmat = as.matrix(data[, c(4,5)])
ordmod = ordinalNet(covmat, as.factor(data$stq))
summary(ordmod)
coef(ordmod, matrix=TRUE)
#kfold cv
set.seed(123)
ordfit = ordinalNetTune(covmat, as.factor(data$stq), family = "cumulative",
link = "logit", parallelTerms = TRUE, nonparallelTerms = TRUE,
warn = FALSE, printProgress = FALSE)
head(ordfit$loglik)
bestLambdaIndex = which.max(rowMeans(ordfit$loglik))
head(coef(ordfit$fit, matrix = TRUE, whichLambda = bestLambdaIndex))
#kfold cv
set.seed(12)
ordfit = ordinalNetTune(covmat, as.factor(data$stq), family = "cumulative",
link = "logit", parallelTerms = TRUE, nonparallelTerms = TRUE,
warn = FALSE, printProgress = FALSE)
#kfold cv
set.seed(123)
ordfit = ordinalNetTune(covmat, as.factor(data$stq), family = "cumulative",
link = "logit", parallelTerms = TRUE, nonparallelTerms = TRUE,
warn = FALSE, printProgress = FALSE)
#kfold cv
set.seed(12)
ordfit = ordinalNetTune(covmat, as.factor(data$stq), family = "cumulative",
link = "logit", parallelTerms = TRUE, nonparallelTerms = TRUE,
warn = FALSE, printProgress = FALSE)
head(ordfit$loglik)
bestLambdaIndex = which.max(rowMeans(ordfit$loglik))
head(coef(ordfit$fit, matrix = TRUE, whichLambda = bestLambdaIndex))
##finding ajustment value##
group = split.data.frame(data, data$stq)
adj <- function(AllP, Test1){
adjust = ave(AllP)-ave(Test1)
return(adjust)
}
adjval = NULL
for (k in group){
adjval = c(adjval,adj(k$allp, k$test1))
}
data$adjval = adjval
data$adjusted_test1 = data$test1 + adjval
#### Simulate the experimental data ####
set.seed = (2)
expAllp.sim = rnorm(200, mean = 24.55, sd = 4.735)
set.seed = (3)
expTest1.sim = rnorm(200, mean = 18.01, sd = 2.77)
expsim = as.data.frame(cbind(expAllp.sim, expTest1.sim))
expsim$ztest1 = (expsim$expTest1.sim - mean(expsim$expTest1.sim))/sd(expsim$expTest1.sim)
expsim$zallP = (expsim$expAllp.sim - mean(expsim$expAllp.sim))/sd(expsim$expAllp.sim)
#### calculating experimental starting quantity ####
probmat = predict(ordfit$fit, as.matrix(expsim[,3:4]))
probmat[1:10,]
#### calculating experimental starting quantity ####
probmat = predict(ordfit$fit, as.matrix(expsim[,3:4]),options(scipen=999))
#### calculating experimental starting quantity ####
probmat = format(predict(ordfit$fit, as.matrix(expsim[,3:4])), scientific = FALSE)
probmat[1:10,]
#### calculating experimental starting quantity ####
probmat = format(predict(ordfit$fit, as.matrix(expsim[,3:4])), options(scipen=999))
#### calculating experimental starting quantity ####
probmat = format(predict(ordfit$fit, as.matrix(expsim[,3:4])), scientific = FALSE)
probmat[1:10,]
#### calculating experimental starting quantity ####
probmat = predict(ordfit$fit, as.matrix(expsim[,3:4]))
options(scipen=999, digits = 4)
probmat[1:10,]
#### calculating experimental starting quantity ####
probmat = predict(ordfit$fit, as.matrix(expsim[,3:4]))
options(scipen=100, digits = 4)
probmat[1:10,]
#### calculating experimental starting quantity ####
probmat = predict(ordfit$fit, as.matrix(expsim[,3:4]))
options(scipen=999)
probmat[1:10,]
install.packages(precrec)
install.packages("precrec")
library('precrec')
math = c(64,50,85,34,56,24,72,63,42,93)
sci = c(68,70,83,33,60,27,74,63,40,96)
plot(math, sci)
abline(lm(sci~math))
plot(math, sci, main = "Association between Math and Science Test Scores")
abline(lm(sci~math))
abs = c(3,5,1,1,3,6,5,3,0,7,8,2,9,0,6,6,2,0,5,7,9,1)
scores = c(65,50,95,85,50,34,70,56,100,24,45,71,30,95,55,42,90,92,60,50,10,80)
plot(abs, math, main = "Plot of number of Absences vs. Math Scores")
abline(lm(scores~abs))
length(abs)
length(scores)
abs = c(3,5,1,1,3,6,5,3,0,7,8,2,9,0,6,6,2,0,5,7,9,1)
scores = c(65,50,95,85,50,34,70,56,100,24,45,71,30,95,55,42,90,92,60,50,10,80)
plot(abs, math, main = "Plot of number of Absences vs. Math Scores")
plot(abs, scores, main = "Plot of number of Absences vs. Math Scores")
abline(lm(scores~abs))
summary(lm(scores~abs))
predict(lm(scores~abs), 3)
model = lm(scores~abs)
abline(model)
summary(model)
predict(model, 3)
predict(3, model)
predict(model, 3)
predict(model, as.matrix(3)
)
predict(model, c(2,3))
dat = cbind(abs, scores)
model = lm(scores~abs, data = dat)
dat = as.matrix(cbind(abs, scores))
model = lm(scores~abs, data = dat)
dat = as.data.frame(cbind(abs, scores))
plot(abs, scores, main = "Plot of number of Absences vs. Math Scores")
model = lm(scores~abs, data = dat)
abline(model)
summary(model)
predict(model, 3)
predict(model, c(2,3))
math = c(64,50,85,34,56,24,72,63,42,93)
sci = c(68,70,83,33,60,27,74,63,40,96)
plot(math, sci, main = "Association between Math and Science Test Scores")
abline(lm(sci~math))
abs = c(3,5,1,1,3,6,5,3,0,7,8,2,9,0,6,6,2,0,5,7,9,1)
scores = c(65,50,95,85,50,34,70,56,100,24,45,71,30,95,55,42,90,92,60,50,10,80)
dat = as.data.frame(cbind(abs, scores))
plot(abs, scores, main = "Plot of number of Absences vs. Math Scores")
model = lm(scores~abs, data = dat)
abline(model)
summary(model)
library('dplyr')
library('ordinalNet')
library('precrec')
data(P10N10)
View(P10N10)
head(P10N10)
sscurves <- evalmod(scores = P10N10$scores, labels = P10N10$labels)
plot(sscurves)
plot(sscurves, "PRC")
samp1 <- create_sim_samples(5, 50000, 50000)
View(samp1)
eval1 <- evalmod(scores = samp1$scores, labels = samp1$labels)
View(eval1)
eval1
67*17.5
36*15
36*15+1172.5
1712.5*.75
(67+16)*17.5
((67+16)*17.5+540)*.75
#create the dataset with starting quantites, all products and test 1 cp values
sd.val = 0.2
sd.val.test = 0.1
set.seed(1234)
eps = rnorm(21, 0, sd.val)
set.seed(12345)
eps.test= rnorm(21, 0, sd.val.test)
stq =sort(rep(c(0.010, 0.050, 0.100, 0.500, 1.000, 0.005, 5.000), 3))
allp = (-2.5)*log(stq)+25+eps
test1 = -2.7*log(stq)+23+eps.test
data = as.data.frame(cbind(stq, allp, test1))
data$ztest1 = (data$test1 - mean(data$test1))/sd(data$test1)
data$zallP = (data$allp - mean(data$allp))/sd(data$allp)
View(data)
covmat = as.matrix(data[, c(4,5)])
ordmod = ordinalNet(covmat, as.factor(data$stq))
summary(ordmod)
coef(ordmod, matrix=TRUE)
#kfold cv
set.seed(12)
ordfit = ordinalNetTune(covmat, as.factor(data$stq), family = "cumulative",
link = "logit", parallelTerms = TRUE, nonparallelTerms = TRUE,
warn = FALSE, printProgress = FALSE)
head(ordfit$loglik)
bestLambdaIndex = which.max(rowMeans(ordfit$loglik))
head(coef(ordfit$fit, matrix = TRUE, whichLambda = bestLambdaIndex))
#######################################
####### k-Fold Cross Validation ####### ordinalNet model
#######################################
library(caret)
n = length(calib_subset[,1])
set.seed(1)
f <- 7
folds <- rep_len(1:f, length.out = dim(calib_subset)[1])
folds <- sample(folds, size = dim(calib_subset)[1], replace = F)
table(folds)
n = length(data[,1])
set.seed(1)
f <- 7
folds <- rep_len(1:f, length.out = dim(data)[1])
folds <- sample(folds, size = dim(data)[1], replace = F)
table(folds)
preds = NULL
truth = NULL
for (k in 1:f){
test.ID = which(folds == k)
train_y = data[-test.ID, "startq"]
train_x = data[-test.ID, 2:5]
test_y = data[test.ID, "startq"]
test_x = data[test.ID, 2:5]
truth = c(truth, test_y)
model.fit = ordinalNet(as.matrix(train_x), as.factor(train_y))
preds = c(preds, predict(model.fit, test_x)) #need to fix s.t. results in 9 values rather than 45
}
for (k in 1:f){
test.ID = which(folds == k)
train_y = data[-test.ID, "startq"]
train_x = data[-test.ID, 4:5]
test_y = data[test.ID, "startq"]
test_x = data[test.ID, 4:5]
truth = c(truth, test_y)
model.fit = ordinalNet(as.matrix(train_x), as.factor(train_y))
preds = c(preds, predict(model.fit, test_x)) #need to fix s.t. results in 9 values rather than 45
}
preds = NULL
truth = NULL
for (k in 1:f){
test.ID = which(folds == k)
train_y = data[-test.ID, "stq"]
train_x = data[-test.ID, 4:5]
test_y = data[test.ID, "stq"]
test_x = data[test.ID, 4:5]
truth = c(truth, test_y)
model.fit = ordfit$fit(as.matrix(train_x), as.factor(train_y))
preds = c(preds, predict(model.fit, test_x)) #need to fix s.t. results in 9 values rather than 45
}
set.seed = (2)
expAllp.sim = rnorm(200, mean = 24.55, sd = 4.735)
set.seed = (3)
expTest1.sim = rnorm(200, mean = 18.01, sd = 2.77)
expsim = as.data.frame(cbind(expAllp.sim, expTest1.sim))
expsim$ztest1 = (expsim$expTest1.sim - mean(expsim$expTest1.sim))/sd(expsim$expTest1.sim)
expsim$zallP = (expsim$expAllp.sim - mean(expsim$expAllp.sim))/sd(expsim$expAllp.sim)
#####
#### calculating experimental starting quantity ####
k = 1
test.ID = which(folds == k)
train_y = data[-test.ID, "stq"]
train_x = data[-test.ID, 4:5]
test_y = data[test.ID, "stq"]
test_x = data[test.ID, 4:5]
truth = c(truth, test_y)
model.fit = ordfit$fit(as.matrix(train_x), as.factor(train_y))
model.fit = ordfit$fit(train_x, train_y)
train_x
train_y
model.fit = ordinalNetTune(train_x, train_y)
model.fit = ordinalNetTune(train_x, as.factor(train_y), family = 'cumulative', link = 'logit',
parallelTerms = TRUE, nonparallelTerms = TRUE, want = FALSE,
printProgress = FALSE)
setwd("C:/Users/twili/Desktop/GIThub/Andrew/stapleton_lab/Stress_Splicing/Heirarchical")
### HEIARCHICAL MODEL ###
library(MASS)
library(stringr)
## Ordinal Net package ##
library("ordinalNet")
#### reading in and setting up calibrated data ####
# MONTH 1 (2018_6 / JUNE) CALIBRATED DATA FRAME
calib_data_6 = na.omit(read.csv("../2018_6/calib_2018_6.csv")[,-1])
calib_data_6$ztest1 = (calib_data_6$test1 - mean(calib_data_6$test1))/sd(calib_data_6$test1)
calib_data_6$zallP = (calib_data_6$allP - mean(calib_data_6$allP))/sd(calib_data_6$allP)
calib_data_6$month ='june'
#calib_data_6
# MONTH 2 (2018_8 / AUGUST) CALIBRATED DATA FRAME
calib_data_8 = na.omit(read.csv("../2018_8/calib_2018_8.csv")[,-1])
calib_data_8$ztest1 = (calib_data_8$test1 - mean(calib_data_8$test1))/sd(calib_data_8$test1)
calib_data_8$zallP = (calib_data_8$allP - mean(calib_data_8$allP))/sd(calib_data_8$allP)
calib_data_8$month ='aug'
#calib_data_8
# MONTH 3 (2018_11 / NOVEMBER) CALIBRATED DATA FRAME
calib_data_11 = na.omit(read.csv("../2018_11/calib_2018_11.csv")[,-1])
calib_data_11$ztest1 = (calib_data_11$test1 - mean(calib_data_11$test1))/sd(calib_data_11$test1)
calib_data_11$zallP = (calib_data_11$allP - mean(calib_data_11$allP))/sd(calib_data_11$allP)
calib_data_11$month ='nov'
#calib_data_11
# Combined Calib d.f. for all months
calib_data = rbind(calib_data_6, calib_data_8, calib_data_11)
# Create dummy varible columns for each month
calib_data$june = ifelse(str_detect(calib_data[,6], "june"), 1, 0)
calib_data$aug = ifelse(str_detect(calib_data[,6], "aug"), 1, 0)
calib_data = calib_data[,-6]
# Drop rows containing NA
calib_subset = calib_data[,c(1, 4:7)]
######
#### Plotting calibrated data ####
#graphing log starting quantity to cp values
plot(calib_data$allP,log(calib_data$startq), col = 'red', main = "Hierarchical Log Starting Quanitty vs. Cp Values",
ylab = "log(Starting Quantity)", xlab = "Cp Values" , xlim = c(5, 25), ylim = c(-6, 1))
points(calib_data$test1,log(calib_data$startq), col = 'blue')
abline(lm(log(calib_data$startq)~calib_data$allP), col = 'red')
abline(lm(log(calib_data$startq)~calib_data$test1), col = 'blue')
legend('topright', legend=c("Test 1", "All Products"),
col=c("blue", "red"), lty = 1, cex=0.8)
#graphing log starting quantity to cp values by month
#June
plot(calib_data_6$allP,log(calib_data_6$startq), col = 'red', main = "June Log Starting Quanitty vs. Cp Values",
ylab = "log(Starting Quantity)", xlab = "Cp Values" , xlim = c(5, 25), ylim = c(-6, 1))
points(calib_data_6$test1,log(calib_data_6$startq), col = 'blue')
abline(lm(log(calib_data_6$startq)~calib_data_6$allP), col = 'red')
abline(lm(log(calib_data_6$startq)~calib_data_6$test1), col = 'blue')
legend('topright', legend=c("Test 1", "All Products"),
col=c("blue", "red"), lty = 1, cex=0.8)
#August
plot(calib_data_8$allP,log(calib_data_8$startq), col = 'red', main = "August Log Starting Quanitty vs. Cp Values",
ylab = "log(Starting Quantity)", xlab = "Cp Values" , xlim = c(5, 25), ylim = c(-6, 1))
points(calib_data_8$test1,log(calib_data_8$startq), col = 'blue')
abline(lm(log(calib_data_8$startq)~calib_data_8$allP), col = 'red')
abline(lm(log(calib_data_8$startq)~calib_data_8$test1), col = 'blue')
legend('topright', legend=c("Test 1", "All Products"),
col=c("blue", "red"), lty = 1, cex=0.8)
#November
plot(calib_data_11$allP,log(calib_data_11$startq), col = 'red', main = "November Log Starting Quanitty vs. Cp Values",
ylab = "log(Starting Quantity)", xlab = "Cp Values" , xlim = c(5, 25), ylim = c(-6, 1))
points(calib_data_11$test1,log(calib_data_11$startq), col = 'blue')
abline(lm(log(calib_data_11$startq)~calib_data_11$allP), col = 'red')
abline(lm(log(calib_data_11$startq)~calib_data_11$test1), col = 'blue')
legend('topright', legend=c("Test 1", "All Products"),
col=c("blue", "red"), lty = 1, cex=0.8)
#####
###### POLR models ######
# Ordinal Logistic Regression Model
model = polr(as.factor(calib_subset$startq) ~ ., data=calib_subset, Hess = TRUE)
#(summary(model))
(ctable <- coef(summary(model)))
## calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
options(scipen=999)
## combined table
(ctable <- cbind(ctable, "p value" = p))
###### Ordinal Net models #######
#define ordinal model starq~zallP+ztest1+month
ordmod = ordinalNet(as.matrix(calib_subset[,2:5]), as.factor(calib_subset$startq))
summary(ordmod)
coef(ordmod, matrix=TRUE)
#kfold cv
set.seed(3)
ordfit = ordinalNetTune(as.matrix(calib_subset[,2:5]), as.factor(calib_subset$startq), family = "cumulative",
link = "logit", parallelTerms = TRUE, nonparallelTerms = TRUE,
warn = FALSE, printProgress = FALSE)
head(ordfit$loglik)
bestLambdaIndex = which.max(rowMeans(ordfit$loglik))
head(coef(ordfit$fit, matrix = TRUE, whichLambda = bestLambdaIndex))
###### Experimental Data #######
# MONTH 1 (2018_8 / AUGUST) EXPERIMENTAL DATA FRAME
exp_data_8 = na.omit(read.csv("../2018_8/exp_2018_8.csv")[,-1])
exp_data_8$ztest1 = (exp_data_8$test1 - mean(exp_data_8$test1))/sd(exp_data_8$test1)
exp_data_8$zallP = (exp_data_8$allP - mean(exp_data_8$allP))/sd(exp_data_8$allP)
exp_data_8$month ='aug'
exp_data_8$sampleID.exp = as.factor(exp_data_8$sampleID.exp)
#exp_data_8
# MONTH 2 (2018_6 / JUNE) EXPERIMENTAL DATA FRAME
exp_data_6 = na.omit(read.csv("../2018_6/exp_2018_6.csv")[,-c(1,5,6)])
exp_data_6$ztest1 = (exp_data_6$test1 - mean(exp_data_6$test1))/sd(exp_data_6$test1)
exp_data_6$zallP = (exp_data_6$allP - mean(exp_data_6$allP))/sd(exp_data_6$allP)
exp_data_6$month ='june'
#exp_data_6
# MONTH 3 (2018_11 / NOVEMBER) EXPERIMENTAL DATA FRAME
exp_data_11 = na.omit(read.csv("../2018_11/exp_2018_11.csv")[,-1])
exp_data_11$ztest1 = (exp_data_11$test1 - mean(exp_data_11$test1))/sd(exp_data_11$test1)
exp_data_11$zallP = (exp_data_11$allP - mean(exp_data_11$allP))/sd(exp_data_11$allP)
exp_data_11$month ='nov'
exp_data_11$sampleID.exp = as.factor(exp_data_11$sampleID.exp)
#exp_data_11
# Combined exp d.f. for all months
exp_data = rbind(exp_data_6, exp_data_8, exp_data_11)
# Create dummy varible columns for each month
exp_data$june = ifelse(str_detect(exp_data[,6], "june"), 1, 0)
exp_data$aug = ifelse(str_detect(exp_data[,6], "aug"), 1, 0)
exp_data = exp_data[,-6]
# Drop rows containing NA
exp_subset = exp_data[,c(1, 4:7)]
#### calculating experimental starting quantity ####
probmat = predict(ordfit$fit, as.matrix(exp_subset[,2:5]))
probmat[1:10,]
##### finding adjustment value and adjusted test 1 in calibrated #####
group = split.data.frame(calib_data, calib_data$startq)
adj <- function(AllP, Test1){
adjust = ave(AllP)-ave(Test1)
return(adjust)
}
adjval = NULL
for (k in group){
adjval = c(adjval,adj(k$allP, k$test1))
}
calib_data$adjval = adjval
calib_data$adjusted_test1 = calib_data$test1 + adjval
##### Creating a dataframe with the stq and adjustment values #########
# used as a key for the adjustment per start q
calib_adj = as.data.frame(cbind(as.numeric(as.character(unique(calib_data$startq))), unique(calib_data$adjval)))
# Rename columns
colnames(calib_adj)=c("startq", "adj")
# Apply probability matrix to the adjustment values
apply(probmat, 1, function(x) x*calib_adj$adj)
exp_data$exp.adjust = colSums(apply(probmat, 1, function(x) x*calib_adj$adj))
# Create new column with stress product (VQTL input)
exp_data$exp.adjustTest1 = exp_data$test1.exp+exp_data$exp.adjust
exp_data$stress = exp_data$allP.exp - exp_data$exp.adjustTest1
boxplot(exp_data$stress)
boxplot(exp_data$stress, exp_data$test1.exp)
boxplot(exp_data$allP.exp, exp_data$test1.exp, exp_data$stress, main = "Boxplot of Experimental All Products, Test 1, and Stress")
boxplot(exp_data$allP.exp, exp_data$test1.exp, exp_data$stress, main = "Boxplot of Experimental All Products, Test 1, and Stress"
names =c("All Products", "Test 1", "Stress"))
boxplot(exp_data$allP.exp, exp_data$test1.exp, exp_data$stress, main = "Boxplot of Experimental All Products, Test 1, and Stress",
names =c("All Products", "Test 1", "Stress"))
hist(exp_data$allP.exp, exp_data$test1.exp, exp_data$stress, main = "Boxplot of Experimental All Products, Test 1, and Stress",
names =c("All Products", "Test 1", "Stress"), xlab = "Cp value")
boxplot(exp_data$allP.exp, exp_data$test1.exp, exp_data$stress, main = "Boxplot of Experimental All Products, Test 1, and Stress",
names =c("All Products", "Test 1", "Stress"), xlab = "Cp value", col =c("blue", "red", "green"))
boxplot(exp_data$allP.exp, exp_data$test1.exp, exp_data$stress, main = "Boxplot of Experimental All Products, Test 1, and Stress",
names =c("All Products", "Test 1", "Stress"), ylab = "Cp value", col =c("blue", "red", "green"))
summary(exp_data$stress)
head(exp_data$stress)
head(exp_data$stress, 20)
head(exp_data$stress)
summary(exp_data$stress)
head(exp_data$stress,20)
t(summary(exp_data$stress))
summary(exp_data$test1.exp)
summary(exp_data$allP.exp
)
