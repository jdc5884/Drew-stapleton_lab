exp_data$test1.exp.ln = log(exp_data$test1.exp)
exp_data$allP.exp.ln = log(exp_data$allP.exp)
### CONFUSTION MATRIX ###
library(caret)
numLlvs <- 4
confusionMatrix(
factor(sample(rep(letters[1:numLlvs], 200), 50)),
factor(sample(rep(letters[1:numLlvs], 200), 50)))
group = split.data.frame(calib_data, calib_data$startq)
adj <- function(AllP, Test1){
adjust = ave(AllP)-ave(Test1)
return(adjust)
}
adjval = NULL
for (k in group){
adjval = c(adjval,adj(k$allP, k$test1))
}
calib_data$adjval = adjval
calib_data$adjusted_test1 = calib_data$test1 + adjval
##### Finding the average adjusted test 1 #########
#average function takes the mean of each
average <- function(col1){
avg = NULL;
for (i in col1){
avg = c(avg,mean(col1))
}
return(avg)
}
##Subset data by starting quantity
group = split.data.frame(calib_data, calib_data$startq)
adj.test1.avg = NULL;
for (k in group){
adj.test1.avg = c(adj.test1.avg, average(k$adjusted_test1))
}
print(adj.test1.avg)
calib_adj = unique(as.data.frame(cbind(as.numeric(as.character(calib_data$startq)), adj.test1.avg)))
# Rename columns
colnames(calib_adj)=c("startq", "adj.test1.avg")
setwd("C:/Users/twili/Desktop/GIThub/Andrew/stapleton_lab/Stress_Splicing/2018_11")
library(tidyr)
library(pracma)
library(stringr)
library(tidyverse)
library(dplyr)
library(MASS)
library(glm.predict)
library(Stack)
# In the case of having one CSV containing calculated derivatives, use this code:
#deriv=read.csv(file = "(YEAR_MONTH_PLATE_qPCR_output.csv", header=FALSE)
deriv_complete=read.csv(file = "2018_6_1_qPCR_Output.csv", header=FALSE)
deriv.1<-read.csv(file = "2018_11_1_qPCR_Output.csv", header=FALSE)
deriv.2<-read.csv(file = "2018_11_2_qPCR_Output.csv", header=FALSE)
deriv_complete=as.data.frame(cbind(deriv.1, deriv.2))
##########################################################
################### Initial Data Framing #################
##########################################################
deriv = deriv_complete
# Remove extra column
deriv = deriv[,-1]
# Transpose derivatives to be in equivalent format as raw plate data
deriv = as.data.frame(t(deriv), header=TRUE)
# Rename columns
colnames(deriv)=c("plateID", "reaction_type", "sampleID", "starting_quantity", "cpD1", "cpD2")
### Removing NTC and gblock-Minus values ###
# Indicate if sample is NTC (negative control)
deriv['sampleID_NTC'] = grepl('NTC', deriv$sampleID)
# Remove NTC samples, indicator (T/F) column, and cpD2 values
ntc = which(deriv$sampleID_NTC)
deriv = deriv[-ntc,]
deriv = deriv[,-c(6,7)]
# Indicate if sample is 'Plus' or 'Minus'
deriv['sampleID_Minus'] = grepl('minus', deriv$sampleID)
# Remove 'Minus' values (include only gblock+ values), and indicator (T/F) column
minus = which(deriv$sampleID_Minus)
# IF "minus" RETURNS EMPTY VALUES, COMMENT OUT COMMAND BELOW
deriv = deriv[-minus,]
deriv = deriv[,-6]
# Remove two extra label rows from center of data frame
deriv['label.row'] = grepl('3', deriv$starting_quantity)
extra = which(deriv$label.row)
deriv = deriv[-extra,]
deriv = deriv[,-6]
deriv$cpD1 = as.numeric(as.character(deriv$cpD1))
### COMPLETED INITIAL DATA FRAMING ###
##########################################################
############ Removing Ununsual Observations ##############
##########################################################
# Remove unusual observations from initial data frame (CT value less than 10)
deriv = deriv %>% filter(deriv$cpD1 >= 10)
# Read in raw cycle data - may need to combine multiple files
cycle1 = read.csv(file = "2018_11_1_plate.csv", header = FALSE)
cycle2 = read.csv(file = "2018_11_2_plate.csv", header = FALSE)
cycle = as.data.frame(cbind(cycle1, cycle2))
# Create complete set of reaction data (derivative and cycle)
reaction = Stack(deriv_complete, cycle1)
# Remove repeat labeling
replace = reaction[7:10,]
reaction = reaction[-c(1:4, 7:10),]
reaction = Stack(replace, reaction)
# Transpose so column headers at top
reaction = as.data.frame(t(reaction))
reaction = reaction[,-c(6:7)]
# Replace column names with first row
colnames(reaction) <- as.character(unlist(reaction[1,]))
reaction = reaction[-1,]
colnames(reaction)[5] = "cpD1"
reaction$cpD1 = as.numeric(as.character(reaction$cpD1))
# Filter unusual observations (CT value less than 10)
unusual_obs_2018_11 = reaction %>% filter(reaction$cpD1 < 10)
# Write CSV file
#write.csv(unusual_obs_2018_11, file="Unusual_Obs_2018_11.csv")
### COMPLETED UNUSUAL OBSERVATIONS REMOVAL/REPORTING ###
##########################################################
################# Calibrated Data Framing ################
##########################################################
# Create/Write data frame for Calibrated values
calib_data = deriv %>% filter(str_detect(sampleID, "g"))
# Sort by starting quantity
calib_data = calib_data[order(calib_data$starting_quantity),]
calib_data$starting_quantity = as.numeric(as.character(calib_data$starting_quantity))
calib_data$cpD1 = as.numeric(as.character(calib_data$cpD1))
test1 = filter(calib_data, reaction_type=="test1")[,5]
allP = filter(calib_data, reaction_type=="all_products")[,4:5]
# Combine test1 and allP obs, with NA in blank cells
calib_data = as.data.frame(cbind.fill(allP, test1, fill = NA))
colnames(calib_data) = c("startq", 'allP', "test1")
# Format starting quantity values as decimals, not scientific notation
calib_data$startq=as.factor(format(calib_data$startq, scientific=FALSE))
calib_data$startq=as.factor(calib_data$startq)
#write.csv(calib_data, file = "calib_2018_11.csv")
### COMPLETED CALIBRATED DATA FRAME ###
##########################################################
############### Experimental Data Framing ################
##########################################################
# Create/Write data frame for Experimental values
exp_data = deriv %>% filter(str_detect(sampleID, "g")==FALSE)
# Sort by starting quantity
exp_data = exp_data[order(exp_data$starting_quantity),]
# # Remove first and last rows (unnecessary labeling)
# exp_data = exp_data[-1,]
# exp_data = exp_data[-nrow(exp_data),]
exp_data$cpD1 = as.numeric(as.character(exp_data$cpD1))
# Order data by sampleID
exp_data = exp_data[order(exp_data$sampleID),]
### Finding invalid observations ###
# Find invalid observations - Find counts of each unique sampleID; remove ones with count not equal to 2 from data frame
counts = as.data.frame(table(exp_data$sampleID))
countsne2 = as.data.frame(filter(counts, !counts$Freq==2))
countsne2$Var1 = as.numeric(as.character(countsne2$Var1))
# Remove observations with count not equal to 2 from data set
exp_data = exp_data[!exp_data$sampleID %in% countsne2$Var1,]
# Create empty vectors for for-loop to input cpD1 values
test1.exp = c()
allP.exp = c()
sampleID.exp = c()
# For loop -- iterating thru starting quantity and reaction type to return cpD1 values
for(i in 1:length(exp_data$sampleID)){
id.exp = toString(exp_data$sampleID[i])
if(i %% 2 == 1){
sampleID.exp = c(sampleID.exp, id.exp)
}
val = toString(exp_data$reaction_type[i])
if(strcmp(val, "test1")){
test1.exp = c(test1.exp, exp_data$cpD1[i])
}
if(strcmp(val, "all_products")){
allP.exp = c(allP.exp, exp_data$cpD1[i])
}
}
# Bind test1 and allProd cpD1 values by sample ID, convert to data frame
exp_data = as.data.frame(cbind(sampleID.exp, test1.exp, allP.exp))
exp_data$test1.exp = as.numeric(as.character(exp_data$test1.exp))
exp_data$allP.exp = as.numeric(as.character(exp_data$allP.exp))
#write.csv(exp_data, file = "exp_2018_11.csv")
### COMPLETED EXPERIMENTAL DATA FRAME ###
setwd("C:/Users/twili/Desktop/GIThub/Andrew/stapleton_lab/Stress_Splicing/ByMonthAnalysis")
#CALIBRATED DATA FRAME
calib_data_6 = na.omit(read.csv("../2018_6/calib_2018_6.csv")[,-1])
calib_data_6$ztest1 = (calib_data_6$test1 - mean(calib_data_6$test1))/sd(calib_data_6$test1)
calib_data_6$zallP = (calib_data_6$allP - mean(calib_data_6$allP))/sd(calib_data_6$allP)
calib_data_6$month ='june'
#calib_data_6
library(MASS)
library(stringr)
## Ordinal Net package ##
library("ordinalNet")
View(calib_data_6)
#define ordinal model starq~zallP+ztest1
ordmod6 = ordinalNet(as.matrix(calib_data_6[,4:5]), as.factor(calib_data_6$startq))
summary(ordmod6)
coef(ordmod6, matrix=TRUE)
#kfold cv
set.seed(3)
ordfit6 = ordinalNetTune(as.matrix(calib_data_6[,4:5]), as.factor(calib_data_6$startq), family = "cumulative",
link = "logit", parallelTerms = TRUE, nonparallelTerms = TRUE,
warn = FALSE, printProgress = FALSE)
head(ordfit6$loglik)
bestLambdaIndex = which.max(rowMeans(ordfit6$loglik))
head(coef(ordfit6$fit, matrix = TRUE, whichLambda = bestLambdaIndex))
calib_data_8 = na.omit(read.csv("../2018_8/calib_2018_8.csv")[,-1])
calib_data_8$ztest1 = (calib_data_8$test1 - mean(calib_data_8$test1))/sd(calib_data_8$test1)
calib_data_8$zallP = (calib_data_8$allP - mean(calib_data_8$allP))/sd(calib_data_8$allP)
calib_data_8$month ='aug'
ordmod8 = ordinalNet(as.matrix(calib_data_8[,4:5]), as.factor(calib_data_8$startq))
summary(ordmod8)
coef(ordmod8, matrix=TRUE)
#kfold cv
set.seed(3)
ordfit8 = ordinalNetTune(as.matrix(calib_data_8[,4:5]), as.factor(calib_data_8$startq), family = "cumulative",
link = "logit", parallelTerms = TRUE, nonparallelTerms = TRUE,
warn = FALSE, printProgress = FALSE)
head(ordfit8$loglik)
bestLambdaIndex = which.max(rowMeans(ordfit8$loglik))
head(coef(ordfit8$fit, matrix = TRUE, whichLambda = bestLambdaIndex))
#CALIBRATED DATA FRAME
calib_data_11 = na.omit(read.csv("../2018_11/calib_2018_11.csv")[,-1])
calib_data_11$ztest1 = (calib_data_11$test1 - mean(calib_data_11$test1))/sd(calib_data_11$test1)
calib_data_11$zallP = (calib_data_11$allP - mean(calib_data_11$allP))/sd(calib_data_11$allP)
calib_data_11$month ='nov'
#calib_data_11
#define ordinal model starq~zallP+ztest1
ordmod11 = ordinalNet(as.matrix(calib_data_11[,4:5]), as.factor(calib_data_11$startq))
summary(ordmod11)
coef(ordmod11, matrix=TRUE)
#kfold cv
set.seed(3)
ordfit11 = ordinalNetTune(as.matrix(calib_data_11[,4:5]), as.factor(calib_data_11$startq), family = "cumulative",
link = "logit", parallelTerms = TRUE, nonparallelTerms = TRUE,
warn = FALSE, printProgress = FALSE)
head(ordfit11$loglik)
bestLambdaIndex = which.max(rowMeans(ordfit11$loglik))
head(coef(ordfit11$fit, matrix = TRUE, whichLambda = bestLambdaIndex))
########## End of November ##########
# MONTH 1 (2018_6 / JUNE) EXPERIMENTAL DATA FRAME
exp_data_6 = na.omit(read.csv("../2018_6/exp_2018_6.csv")[,-c(1,5,6)])
exp_data_6$ztest1 = (exp_data_6$test1 - mean(exp_data_6$test1))/sd(exp_data_6$test1)
exp_data_6$zallP = (exp_data_6$allP - mean(exp_data_6$allP))/sd(exp_data_6$allP)
exp_data_6$month ='june'
#exp_data_6
#create a prob matrix using the model and month
probmat = predict(ordfit6$fit, as.matrix(exp_subset[,2:5]))
probmat[1:10,]
probmat = predict(ordfit6$fit, as.matrix(exp_data_6[,4:5]))
probmat[1:10,]
#create a prob matrix using the model and month
probmat6 = predict(ordfit6$fit, as.matrix(exp_data_6[,4:5]))
# MONTH 3 (2018_11 / NOVEMBER) EXPERIMENTAL DATA FRAME
exp_data_11 = na.omit(read.csv("../2018_11/exp_2018_11.csv")[,-1])
exp_data_11$ztest1 = (exp_data_11$test1 - mean(exp_data_11$test1))/sd(exp_data_11$test1)
exp_data_11$zallP = (exp_data_11$allP - mean(exp_data_11$allP))/sd(exp_data_11$allP)
exp_data_11$month ='nov'
exp_data_11$sampleID.exp = as.factor(exp_data_11$sampleID.exp)
#exp_data_11
#create a prob matrix using the model and month
probmat11 = predict(ordfit11$fit, as.matrix(exp_data_11[,4:5]))
probmat11[1:10,]
group = split.data.frame(calib_data_6, calib_data_6$startq)
adj <- function(AllP, Test1){
adjust = ave(AllP)-ave(Test1)
return(adjust)
}
adjval = NULL
for (k in group){
adjval = c(adjval,adj(k$allP, k$test1))
}
calib_data_6$adjval = adjval
calib_data_6$adjusted_test1 = calib_data$test1 + adjval
calib_data_6$adjusted_test1 = calib_data_6$test1 + adjval
#### finding adjustment value and adjusted test 1 in calibrated #####
group = split.data.frame(calib_data_8, calib_data_8$startq)
adj <- function(AllP, Test1){
adjust = ave(AllP)-ave(Test1)
return(adjust)
}
adjval = NULL
for (k in group){
adjval = c(adjval,adj(k$allP, k$test1))
}
calib_data_8$adjval = adjval
calib_data_8$adjusted_test1 = calib_data_8$test1 + adjval
####################### End of August #######################
View(calib_data_8)
#### finding adjustment value and adjusted test 1 in calibrated #####
group = split.data.frame(calib_data_11, calib_data_11$startq)
adj <- function(AllP, Test1){
adjust = ave(AllP)-ave(Test1)
return(adjust)
}
adjval = NULL
for (k in group){
adjval = c(adjval,adj(k$allP, k$test1))
}
calib_data_11$adjval = adjval
calib_data_11$adjusted_test1 = calib_data_11$test1 + adjval
###################### End of November ######################
View(calib_data_11)
adj1111$adjval = adjval
adj11 = cbind(adjval, calib_data_11$test1 +adjval)
View(adj11)
adj11 = cbind(unique(calib_data_11$startq), unique(adjval))
colnames(adj11) = c("Startq", "adjval")
colnames(adj11) = c("Startq", "adj")
colnames(adj11) = c("startq", "adj")
group = split.data.frame(calib_data_6, calib_data_6$startq)
adj <- function(AllP, Test1){
adjust = ave(AllP)-ave(Test1)
return(adjust)
}
adjval = NULL
for (k in group){
adjval = c(adjval,adj(k$allP, k$test1))
}
adj6 = cbind(unique(calib_data_6$startq), unique(adjval))
colnames(adj6) = c("startq", "adj")
##### finding adjustment value and adjusted test 1 in calibrated #####
group = split.data.frame(calib_data_8, calib_data_8$startq)
adj <- function(AllP, Test1){
adjust = ave(AllP)-ave(Test1)
return(adjust)
}
adjval = NULL
for (k in group){
adjval = c(adjval,adj(k$allP, k$test1))
}
adj8 = cbind(unique(calib_data_8$startq), unique(adjval))
colnames(adj8) = c("startq", "adj")
View(exp_data_6)
#convert adjustment from picograms to femtograms (1:1000)
adj6$adj = (adj6$adj)*1000
adj6 = cbind(unique(calib_data_6$startq), unique(adjval))
?as.dataframe()
?as.data.frame()
adj6 = as.data.frame(cbind(as.factor(unique(calib_data_6$startq)), unique(adjval)))
#convert adjustment from picograms to femtograms (1:1000)
adj6$adj = (adj6$adj)*1000
adj6 = cbind(as.factor(unique(calib_data_6$startq)), unique(adjval))
colnames(adj6) = c("startq", "adj")
adj6$adj
adj6 = as.matrix(cbind(as.factor(unique(calib_data_6$startq)), unique(adjval)))
colnames(adj6) = c("startq", "adj")
adj6 = as.data.frame(cbind(as.factor(unique(calib_data_6$startq)), unique(adjval)))
colnames(adj6) = c("startq", "adj")
#convert adjustment from picograms to femtograms (1:1000)
adj6$adj = (adj6$adj)*1000
# Apply probability matrix to the adjustment values using matrix multiplication
exp_data$exp.adjust = probmat%*%calib_adj$adj
exp_data_6[,c(2,3)] = exp_data[,c(2,3)]*1000
# Apply probability matrix to the adjustment values using matrix multiplication
exp_data_6$exp.adjust = probmat%*%adj6$adj
# Create new column with stress product (VQTL input)
exp_data_6$exp.adjustTest1 = exp_data_6$test1.exp+exp_data_6$exp.adjust
# convert allP and adjusted test 1 to femtograms
exp_data_6$stress = exp_data_6$allP.exp - exp_data_6$exp.adjustTest1
# convert test1 and allp to femtograms
exp_data_6[,c(2,3)] = exp_data_6[,c(2,3)]*1000
# Apply probability matrix to the adjustment values using matrix multiplication
exp_data_6$exp.adjust = probmat%*%adj6$adj
# Create new column with stress product (VQTL input)
exp_data_6$exp.adjustTest1 = exp_data_6$test1.exp+exp_data_6$exp.adjust
# convert allP and adjusted test 1 to femtograms
exp_data_6$stress = exp_data_6$allP.exp - exp_data_6$exp.adjustTest1
summary(exp_data_6$stress)
boxplot(exp_data_6$stress)
adj8 = as.data.frame(cbind(as.factor(unique(calib_data_8$startq)), unique(adjval)))
colnames(adj8) = c("startq", "adj")
#convert adjustment from picograms to femtograms (1:1000)
adj8$adj = (adj8$adj)*1000
# convert test1 and allp to femtograms
exp_data_8[,c(2,3)] = exp_data_8[,c(2,3)]*1000
# Apply probability matrix to the adjustment values using matrix multiplication
exp_data_8$exp.adjust = probmat%*%adj8$adj
# Create new column with stress product (VQTL input)
exp_data_8$exp.adjustTest1 = exp_data_8$test1.exp+exp_data_8$exp.adjust
# convert allP and adjusted test 1 to femtograms
exp_data_8$stress = exp_data_8$allP.exp - exp_data_8$exp.adjustTest1
# MONTH 2 (2018_8 / AUGUST) EXPERIMENTAL DATA FRAME
exp_data_8 = na.omit(read.csv("../2018_8/exp_2018_8.csv")[,-1])
exp_data_8$ztest1 = (exp_data_8$test1 - mean(exp_data_8$test1))/sd(exp_data_8$test1)
exp_data_8$zallP = (exp_data_8$allP - mean(exp_data_8$allP))/sd(exp_data_8$allP)
exp_data_8$month ='aug'
exp_data_8$sampleID.exp = as.factor(exp_data_8$sampleID.exp)
#exp_data_8
#create a prob matrix using the model and month
probmat8 = predict(ordfit8$fit, as.matrix(exp_data_8[,4:5]))
probmat8[1:10,]
##### finding adjustment value and adjusted test 1 in calibrated #####
group = split.data.frame(calib_data_8, calib_data_8$startq)
adj <- function(AllP, Test1){
adjust = ave(AllP)-ave(Test1)
return(adjust)
}
adjval = NULL
for (k in group){
adjval = c(adjval,adj(k$allP, k$test1))
}
adj8 = as.data.frame(cbind(as.factor(unique(calib_data_8$startq)), unique(adjval)))
colnames(adj8) = c("startq", "adj")
#convert adjustment from picograms to femtograms (1:1000)
adj8$adj = (adj8$adj)*1000
# convert test1 and allp to femtograms
exp_data_8[,c(2,3)] = exp_data_8[,c(2,3)]*1000
# Apply probability matrix to the adjustment values using matrix multiplication
exp_data_8$exp.adjust = probmat%*%adj8$adj
# Create new column with stress product (VQTL input)
exp_data_8$exp.adjustTest1 = exp_data_8$test1.exp+exp_data_8$exp.adjust
# convert allP and adjusted test 1 to femtograms
exp_data_8$stress = exp_data_8$allP.exp - exp_data_8$exp.adjustTest1
summary(exp_data_8$stress)
# Apply probability matrix to the adjustment values using matrix multiplication
exp_data_8$exp.adjust = probmat%*%adj8$adj
dim(exp_data_8)
length(adj8$adj)
# Apply probability matrix to the adjustment values using matrix multiplication
exp_data_8$exp.adjust = probmat8%*%adj8$adj
# Create new column with stress product (VQTL input)
exp_data_8$exp.adjustTest1 = exp_data_8$test1.exp+exp_data_8$exp.adjust
# convert allP and adjusted test 1 to femtograms
exp_data_8$stress = exp_data_8$allP.exp - exp_data_8$exp.adjustTest1
summary(exp_data_8$stress)
boxplot(exp_data_8$stress)
adj11 = as.data.frame(cbind(as.factor(unique(calib_data_11$startq)), unique(adjval)))
colnames(adj11) = c("startq", "adj")
#convert adjustment from picograms to femtograms (1:1000)
adj11$adj = (adj11$adj)*1000
# convert test1 and allp to femtograms
exp_data_11[,c(2,3)] = exp_data_11[,c(2,3)]*1000
# Apply probability matrix to the adjustment values using matrix multiplication
exp_data_11$exp.adjust = probmat8%*%adj11$adj
# Create new column with stress product (VQTL input)
exp_data_11$exp.adjustTest1 = exp_data_11$test1.exp+exp_data_11$exp.adjust
# convert allP and adjusted test 1 to femtograms
exp_data_11$stress = exp_data_11$allP.exp - exp_data_11$exp.adjustTest1
summary(exp_data_11$stress)
boxplot(exp_data_11$stress)
###################### End of November ######################
# Apply probability matrix to the adjustment values using matrix multiplication
exp_data_11$exp.adjust = probmat11%*%adj11$adj
# Create new column with stress product (VQTL input)
exp_data_11$exp.adjustTest1 = exp_data_11$test1.exp+exp_data_11$exp.adjust
# convert allP and adjusted test 1 to femtograms
exp_data_11$stress = exp_data_11$allP.exp - exp_data_11$exp.adjustTest1
summary(exp_data_11$stress)
boxplot(exp_data_11$stress)
tail(exp_data_11$stress)
tail(sort(exp_data_11$stress))
head(sort(exp_data_11$stress))
head(sort(exp_data_11$stress), 20)
### analyzing negative stress ###
negstress11 = na.omit(ifelse(exp_data_11$stress<0,exp_data_11$stress,NA))
hist(negstress_11, col = "light green")
hist(negstress11, col = "light green")
length(negstress11)/length(exp_data_11$stress)
head(sort(exp_data_8$stress), 20)
negstress8 = na.omit(ifelse(exp_data_8$stress<0,exp_data_8$stress,NA))
hist(negstress8, col = "light green")
length(negstress8)/length(exp_data_8$stress)
adj6 = as.data.frame(cbind(as.factor(unique(calib_data_6$startq)), unique(adjval)))
colnames(adj6) = c("startq", "adj")
#convert adjustment from picograms to femtograms (1:1000)
adj6$adj = (adj6$adj)*1000
# convert test1 and allp to femtograms
exp_data_6[,c(2,3)] = exp_data_6[,c(2,3)]*1000
# Apply probability matrix to the adjustment values using matrix multiplication
exp_data_6$exp.adjust = probmat6%*%adj6$adj
# Create new column with stress product (VQTL input)
exp_data_6$exp.adjustTest1 = exp_data_6$test1.exp+exp_data_6$exp.adjust
# convert allP and adjusted test 1 to femtograms
exp_data_6$stress = exp_data_6$allP.exp - exp_data_6$exp.adjustTest1
summary(exp_data_6$stress)
boxplot(exp_data_6$stress)
head(sort(exp_data_6$stress), 20)
### analyzing negative stress ###
negstress6 = na.omit(ifelse(exp_data_6$stress<0,exp_data_6$stress,NA))
hist(negstress6, col = "light green")
length(negstress6)/length(exp_data_6$stress) # 7.14% of stress is negative
plot(calib_data_6$allP,log(calib_data_6$startq), col = 'red', main = "June Log Starting Quanitty vs. Cp Values",
ylab = "log(Starting Quantity)", xlab = "Cp Values" , xlim = c(5, 25), ylim = c(-6, 1))
points(calib_data_6$test1,log(calib_data_6$startq), col = 'blue')
abline(lm(log(calib_data_6$startq)~calib_data_6$allP), col = 'red')
abline(lm(log(calib_data_6$startq)~calib_data_6$test1), col = 'blue')
legend('topright', legend=c("Test 1", "All Products"),
col=c("blue", "red"), lty = 1, cex=0.8)
coef(ordmod6, matrix=TRUE)
#define ordinal model starq~zallP+ztest1
ordmod6 = ordinalNet(as.matrix(calib_data_6[,4:5]), as.factor(calib_data_6$startq))
summary(ordmod6)
coef(ordmod6, matrix=TRUE)
calib_data_6 = na.omit(read.csv("../2018_6/calib_2018_6.csv")[,-1])
calib_data_6$ztest1 = (calib_data_6$test1 - mean(calib_data_6$test1))/sd(calib_data_6$test1)
calib_data_6$zallP = (calib_data_6$allP - mean(calib_data_6$allP))/sd(calib_data_6$allP)
calib_data_6$month ='june'
#calib_data_6
#define ordinal model starq~zallP+ztest1
ordmod6 = ordinalNet(as.matrix(calib_data_6[,4:5]), as.factor(calib_data_6$startq))
summary(ordmod6)
coef(ordmod6, matrix=TRUE)
#kfold cv
set.seed(3)
ordfit6 = ordinalNetTune(as.matrix(calib_data_6[,4:5]), as.factor(calib_data_6$startq), family = "cumulative",
link = "logit", parallelTerms = TRUE, nonparallelTerms = TRUE,
warn = FALSE, printProgress = FALSE)
head(ordfit6$loglik)
bestLambdaIndex = which.max(rowMeans(ordfit6$loglik))
head(coef(ordfit6$fit, matrix = TRUE, whichLambda = bestLambdaIndex))
summary(exp_data_6$stress)
head(coef(ordfit8$fit, matrix = TRUE, whichLambda = bestLambdaIndex))
summary(exp_data_8$stress)
head(coef(ordfit11$fit, matrix = TRUE, whichLambda = bestLambdaIndex))
coef(ordfit11$fit, matrix = TRUE, whichLambda = bestLambdaIndex)
summary(exp_data_11$stress)
7.14+13.17+29.89
(7.14+13.17+29.89)/3
